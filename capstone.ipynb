{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/rohandwivedi2005/capstone?scriptVersionId=236105214\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","id":"8ec8e56c","metadata":{"papermill":{"duration":0.007234,"end_time":"2025-04-25T17:05:31.747849","exception":false,"start_time":"2025-04-25T17:05:31.740615","status":"completed"},"tags":[]},"source":["# Teacher for google-genai SDK"]},{"cell_type":"markdown","id":"8a7690d2","metadata":{"papermill":{"duration":0.005568,"end_time":"2025-04-25T17:05:31.760063","exception":false,"start_time":"2025-04-25T17:05:31.754495","status":"completed"},"tags":[]},"source":["### **This chatbot is for devlopers who want to learn about the new google-genai SDK or switch from the old sdk to the new SDK**"]},{"cell_type":"markdown","id":"33139416","metadata":{"papermill":{"duration":0.005678,"end_time":"2025-04-25T17:05:31.771268","exception":false,"start_time":"2025-04-25T17:05:31.76559","status":"completed"},"tags":[]},"source":["## Scraping Data\n","\n","First we will scrape the google-genai documentation website for up-to-date latest information about the google-genai SDK. We will do this using `beautifulsoup` which is a Python Library Used for webscraping to extract data from html files."]},{"cell_type":"code","execution_count":1,"id":"34a0cbd8","metadata":{"execution":{"iopub.execute_input":"2025-04-25T17:05:31.784052Z","iopub.status.busy":"2025-04-25T17:05:31.783526Z","iopub.status.idle":"2025-04-25T17:05:38.151693Z","shell.execute_reply":"2025-04-25T17:05:38.150094Z"},"papermill":{"duration":6.377557,"end_time":"2025-04-25T17:05:38.154438","exception":false,"start_time":"2025-04-25T17:05:31.776881","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\r\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\r\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4.1)\r\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\r\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.3.0)\r\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2025.1.31)\r\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.6)\r\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["pip install requests beautifulsoup4"]},{"cell_type":"code","execution_count":2,"id":"9f4bea99","metadata":{"execution":{"iopub.execute_input":"2025-04-25T17:05:38.169589Z","iopub.status.busy":"2025-04-25T17:05:38.169208Z","iopub.status.idle":"2025-04-25T17:05:38.758429Z","shell.execute_reply":"2025-04-25T17:05:38.756904Z"},"papermill":{"duration":0.598539,"end_time":"2025-04-25T17:05:38.760626","exception":false,"start_time":"2025-04-25T17:05:38.162087","status":"completed"},"tags":[]},"outputs":[],"source":["import requests\n","from bs4 import BeautifulSoup\n","from urllib.parse import urljoin, urlparse\n","import time\n","import json\n","import os\n","import re"]},{"cell_type":"code","execution_count":3,"id":"08daa9e1","metadata":{"execution":{"iopub.execute_input":"2025-04-25T17:05:38.775083Z","iopub.status.busy":"2025-04-25T17:05:38.77444Z","iopub.status.idle":"2025-04-25T17:05:55.111077Z","shell.execute_reply":"2025-04-25T17:05:55.109564Z"},"papermill":{"duration":16.347398,"end_time":"2025-04-25T17:05:55.114072","exception":false,"start_time":"2025-04-25T17:05:38.766674","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Saving data to: /kaggle/working/GENAI_SDK_DOCS.txt\n","------------------------------\n","  -> Text extracted and saved for https://googleapis.github.io/python-genai/\n","  -> Text extracted and saved for https://googleapis.github.io/python-genai/genai.html\n","------------------------------\n","Crawling finished.\n","Data saved in Kaggle environment at: /kaggle/working/GENAI_SDK_DOCS.txt\n"]}],"source":["URL_1 = \"https://googleapis.github.io/python-genai/\"\n","URL_2 = \"https://googleapis.github.io/python-genai/genai.html\"\n","LIST = [URL_1,URL_2]\n","OUTPUT_FILE = \"GENAI_SDK_DOCS.txt\"\n","REQUEST_DELAY = 1\n","HEADERS = {'User-Agent': 'SimpleScraper/1.0'}\n","\n","\n","\n","output_path = os.path.join(\"/kaggle/working/\", OUTPUT_FILE)\n","print(f\"Saving data to: {output_path}\")\n","print(\"-\" * 30)\n","\n","try:\n","    with open(output_path, 'w', encoding='utf-8') as f:\n","        for current_url in LIST:\n","            time.sleep(REQUEST_DELAY) # Delay *before* request\n","            response = requests.get(current_url, headers=HEADERS, timeout=15) # Increased timeout slightly\n","            response.raise_for_status() # Check for HTTP errors (4xx, 5xx)\n","        \n","            soup = BeautifulSoup(response.content, 'html.parser')\n","            text = soup.get_text(separator=' ', strip=True)\n","            text = ' '.join(text.split())\n","            if text:\n","                             \n","            \n","                f.write(f\"--- URL: {current_url} ---\\n\") \n","\n","                \n","                f.write(text + \"\\n\")\n","\n","                \n","                f.write(\"\\n\")\n","             \n","\n","                print(f\"  -> Text extracted and saved for {current_url}\")\n","                    \n","            else:\n","                print(f\"  -> No significant text content found for {current_url}. Skipping.\")\n","\n","\n","                \n","               \n","\n","\n","except requests.exceptions.RequestException as e:\n","    print(f\"  -> Network/HTTP Error processing {current_url}: {e}\")\n","except Exception as e:\n","    rint(f\"  -> Error processing {current_url}: {e}\")\n","\n","            \n","\n","except IOError as e:\n","     print(f\"FATAL ERROR: Could not open or write to output file {output_path}: {e}\")\n","\n","print(\"-\" * 30)\n","print(f\"Crawling finished.\")\n","print(f\"Data saved in Kaggle environment at: {output_path}\")\n","\n"]},{"cell_type":"code","execution_count":4,"id":"eff26b14","metadata":{"execution":{"iopub.execute_input":"2025-04-25T17:05:55.128678Z","iopub.status.busy":"2025-04-25T17:05:55.128286Z","iopub.status.idle":"2025-04-25T17:05:55.132922Z","shell.execute_reply":"2025-04-25T17:05:55.131908Z"},"papermill":{"duration":0.01397,"end_time":"2025-04-25T17:05:55.134655","exception":false,"start_time":"2025-04-25T17:05:55.120685","status":"completed"},"tags":[]},"outputs":[],"source":["PATH = output_path #Store this path for later use"]},{"cell_type":"markdown","id":"01436e7b","metadata":{"papermill":{"duration":0.005649,"end_time":"2025-04-25T17:05:55.147774","exception":false,"start_time":"2025-04-25T17:05:55.142125","status":"completed"},"tags":[]},"source":["### This is where the file is stored"]},{"cell_type":"code","execution_count":5,"id":"85bae003","metadata":{"execution":{"iopub.execute_input":"2025-04-25T17:05:55.160939Z","iopub.status.busy":"2025-04-25T17:05:55.160538Z","iopub.status.idle":"2025-04-25T17:05:55.167235Z","shell.execute_reply":"2025-04-25T17:05:55.165959Z"},"papermill":{"duration":0.015364,"end_time":"2025-04-25T17:05:55.169069","exception":false,"start_time":"2025-04-25T17:05:55.153705","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/working/__notebook__.ipynb\n","/kaggle/working/GENAI_SDK_DOCS.txt\n"]}],"source":["import os\n","for dirname, _, filenames in os.walk('/kaggle/working'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))"]},{"cell_type":"markdown","id":"0eceb582","metadata":{"papermill":{"duration":0.005649,"end_time":"2025-04-25T17:05:55.181239","exception":false,"start_time":"2025-04-25T17:05:55.17559","status":"completed"},"tags":[]},"source":["## Embeddings Generation\n","\n","Next, We will generate embeddings for the data we extracted and store the embeddings in a vector data base here we will use cromadb. But first we will split out text file into smaller chunks to be processed by our Embeddings generation model."]},{"cell_type":"code","execution_count":6,"id":"a32f7c20","metadata":{"execution":{"iopub.execute_input":"2025-04-25T17:05:55.194476Z","iopub.status.busy":"2025-04-25T17:05:55.194105Z","iopub.status.idle":"2025-04-25T17:06:44.316125Z","shell.execute_reply":"2025-04-25T17:06:44.314342Z"},"papermill":{"duration":49.131156,"end_time":"2025-04-25T17:06:44.318339","exception":false,"start_time":"2025-04-25T17:05:55.187183","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[33mWARNING: Skipping kfp as it is not installed.\u001b[0m\u001b[33m\r\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\r\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\r\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.7/144.7 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.1/611.1 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m55.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.9/100.9 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m49.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m62.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.4/188.4 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.3/65.3 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.0/119.0 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.1/442.1 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m64.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.9/454.9 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\r\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n","google-api-core 1.34.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<4.0.0dev,>=3.19.5, but you have protobuf 5.29.4 which is incompatible.\r\n","google-cloud-bigtable 2.27.0 requires google-api-core[grpc]<3.0.0dev,>=2.16.0, but you have google-api-core 1.34.1 which is incompatible.\r\n","google-cloud-translate 3.12.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.29.4 which is incompatible.\r\n","pandas-gbq 0.25.0 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\r\n","tensorflow 2.17.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.29.4 which is incompatible.\r\n","tensorflow-decision-forests 1.10.0 requires tensorflow==2.17.0, but you have tensorflow 2.17.1 which is incompatible.\r\n","tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 5.29.4 which is incompatible.\u001b[0m\u001b[31m\r\n","\u001b[0m"]}],"source":["!pip uninstall -qqy jupyterlab kfp  # Remove unused conflicting packages\n","!pip install -qU \"google-genai==1.7.0\" \"chromadb==0.6.3\""]},{"cell_type":"code","execution_count":7,"id":"f6cacfb6","metadata":{"execution":{"iopub.execute_input":"2025-04-25T17:06:44.336201Z","iopub.status.busy":"2025-04-25T17:06:44.335795Z","iopub.status.idle":"2025-04-25T17:06:45.504065Z","shell.execute_reply":"2025-04-25T17:06:45.502797Z"},"papermill":{"duration":1.179366,"end_time":"2025-04-25T17:06:45.505916","exception":false,"start_time":"2025-04-25T17:06:44.32655","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["'1.7.0'"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["from google import genai\n","from google.genai import types\n","\n","from IPython.display import Markdown\n","\n","genai.__version__"]},{"cell_type":"markdown","id":"d947dee0","metadata":{"papermill":{"duration":0.00791,"end_time":"2025-04-25T17:06:45.522685","exception":false,"start_time":"2025-04-25T17:06:45.514775","status":"completed"},"tags":[]},"source":["### Fetch API Key"]},{"cell_type":"code","execution_count":8,"id":"b95e6d53","metadata":{"execution":{"iopub.execute_input":"2025-04-25T17:06:45.541437Z","iopub.status.busy":"2025-04-25T17:06:45.540654Z","iopub.status.idle":"2025-04-25T17:06:45.714575Z","shell.execute_reply":"2025-04-25T17:06:45.713174Z"},"papermill":{"duration":0.185806,"end_time":"2025-04-25T17:06:45.716848","exception":false,"start_time":"2025-04-25T17:06:45.531042","status":"completed"},"tags":[]},"outputs":[],"source":["from kaggle_secrets import UserSecretsClient\n","\n","GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")"]},{"cell_type":"markdown","id":"0bd86a46","metadata":{"papermill":{"duration":0.008325,"end_time":"2025-04-25T17:06:45.734008","exception":false,"start_time":"2025-04-25T17:06:45.725683","status":"completed"},"tags":[]},"source":["### Various Models for generating embeddings"]},{"cell_type":"code","execution_count":9,"id":"321d056e","metadata":{"execution":{"iopub.execute_input":"2025-04-25T17:06:45.752577Z","iopub.status.busy":"2025-04-25T17:06:45.75224Z","iopub.status.idle":"2025-04-25T17:06:46.351529Z","shell.execute_reply":"2025-04-25T17:06:46.35034Z"},"papermill":{"duration":0.610474,"end_time":"2025-04-25T17:06:46.35353","exception":false,"start_time":"2025-04-25T17:06:45.743056","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["models/embedding-001\n","models/text-embedding-004\n","models/gemini-embedding-exp-03-07\n","models/gemini-embedding-exp\n"]}],"source":["\n","client = genai.Client(api_key=GOOGLE_API_KEY)\n","\n","for m in client.models.list():\n","    if \"embedContent\" in m.supported_actions:\n","        print(m.name)\n","        "]},{"cell_type":"markdown","id":"f359b6a2","metadata":{"papermill":{"duration":0.007846,"end_time":"2025-04-25T17:06:46.369862","exception":false,"start_time":"2025-04-25T17:06:46.362016","status":"completed"},"tags":[]},"source":["### Main Function for embeddings generation\n","\n","This function will automatically retry for any potential api errors additionaly every time this function is called it will take the chunks as an argument and return embeddings for the text."]},{"cell_type":"code","execution_count":10,"id":"0a2a55ba","metadata":{"execution":{"iopub.execute_input":"2025-04-25T17:06:46.387516Z","iopub.status.busy":"2025-04-25T17:06:46.387131Z","iopub.status.idle":"2025-04-25T17:06:47.353513Z","shell.execute_reply":"2025-04-25T17:06:47.35209Z"},"papermill":{"duration":0.977817,"end_time":"2025-04-25T17:06:47.355665","exception":false,"start_time":"2025-04-25T17:06:46.377848","status":"completed"},"tags":[]},"outputs":[],"source":["import chromadb\n","from chromadb import Documents, EmbeddingFunction, Embeddings\n","from google.genai import types\n","from google.api_core import retry"]},{"cell_type":"code","execution_count":11,"id":"3cb07723","metadata":{"execution":{"iopub.execute_input":"2025-04-25T17:06:47.375166Z","iopub.status.busy":"2025-04-25T17:06:47.374432Z","iopub.status.idle":"2025-04-25T17:06:47.38186Z","shell.execute_reply":"2025-04-25T17:06:47.380509Z"},"papermill":{"duration":0.0192,"end_time":"2025-04-25T17:06:47.384121","exception":false,"start_time":"2025-04-25T17:06:47.364921","status":"completed"},"tags":[]},"outputs":[],"source":["is_retriable = lambda e: (isinstance(e, genai.errors.APIError) and e.code in {429, 503})\n","\n","class GeminiEmbeddingFunction(EmbeddingFunction):\n","    # Specify whether to generate embeddings for documents, or queries\n","    document_mode = True\n","    \n","\n","    @retry.Retry(predicate=is_retriable)\n","    def __call__(self, input: Documents) -> Embeddings:\n","        if self.document_mode:\n","            embedding_task = \"retrieval_document\"\n","        else:\n","            embedding_task = \"retrieval_query\"\n","\n","        response = client.models.embed_content(\n","            model=\"models/text-embedding-004\",\n","            contents=input,\n","            config=types.EmbedContentConfig(\n","                task_type=embedding_task,\n","            ),\n","        )\n","        return [e.values for e in response.embeddings]"]},{"cell_type":"markdown","id":"de57b161","metadata":{"papermill":{"duration":0.00847,"end_time":"2025-04-25T17:06:47.40098","exception":false,"start_time":"2025-04-25T17:06:47.39251","status":"completed"},"tags":[]},"source":["### Split the text into smaller chunks\n","\n","Here we are splitting the text into chunks of 2000 characters with an overlap of 200 chunks. This is done to keep the context to a minimum . Lets say if the chunks size were larg we will be getting too much unnecessary context for the given query. With short chunks the context will be to the point and precise for the model to answer the questions given by a user"]},{"cell_type":"code","execution_count":12,"id":"80d322a0","metadata":{"execution":{"iopub.execute_input":"2025-04-25T17:06:47.41908Z","iopub.status.busy":"2025-04-25T17:06:47.418676Z","iopub.status.idle":"2025-04-25T17:06:48.189155Z","shell.execute_reply":"2025-04-25T17:06:48.18792Z"},"papermill":{"duration":0.781841,"end_time":"2025-04-25T17:06:48.191359","exception":false,"start_time":"2025-04-25T17:06:47.409518","status":"completed"},"tags":[]},"outputs":[],"source":["from langchain_text_splitters import RecursiveCharacterTextSplitter"]},{"cell_type":"code","execution_count":13,"id":"916f2e85","metadata":{"execution":{"iopub.execute_input":"2025-04-25T17:06:48.211901Z","iopub.status.busy":"2025-04-25T17:06:48.211523Z","iopub.status.idle":"2025-04-25T17:06:48.221479Z","shell.execute_reply":"2025-04-25T17:06:48.220003Z"},"papermill":{"duration":0.023167,"end_time":"2025-04-25T17:06:48.223721","exception":false,"start_time":"2025-04-25T17:06:48.200554","status":"completed"},"tags":[]},"outputs":[],"source":["with open(PATH,\"r\") as f:\n","    text = f.read()"]},{"cell_type":"code","execution_count":14,"id":"2323e92f","metadata":{"execution":{"iopub.execute_input":"2025-04-25T17:06:48.244012Z","iopub.status.busy":"2025-04-25T17:06:48.24358Z","iopub.status.idle":"2025-04-25T17:06:48.822713Z","shell.execute_reply":"2025-04-25T17:06:48.821092Z"},"papermill":{"duration":0.592442,"end_time":"2025-04-25T17:06:48.826047","exception":false,"start_time":"2025-04-25T17:06:48.233605","status":"completed"},"tags":[]},"outputs":[],"source":["CHUNK_SIZE = 2000 # Max number of characters per chunk\n","CHUNK_OVERLAP = 200 # Number of characters to overlap between chunks\n","\n","text_splitter = RecursiveCharacterTextSplitter(\n","    chunk_size=CHUNK_SIZE,\n","    chunk_overlap=CHUNK_OVERLAP,\n","    length_function=len,\n","    is_separator_regex=False,\n",")\n","\n","chunks = text_splitter.split_text(text)"]},{"cell_type":"code","execution_count":15,"id":"4a89d76d","metadata":{"execution":{"iopub.execute_input":"2025-04-25T17:06:48.854515Z","iopub.status.busy":"2025-04-25T17:06:48.8541Z","iopub.status.idle":"2025-04-25T17:06:48.866886Z","shell.execute_reply":"2025-04-25T17:06:48.864492Z"},"papermill":{"duration":0.031368,"end_time":"2025-04-25T17:06:48.87107","exception":false,"start_time":"2025-04-25T17:06:48.839702","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["789\n","1999\n"]}],"source":["print(len(chunks))\n","print(len(chunks[3]))"]},{"cell_type":"markdown","id":"c006cea8","metadata":{"papermill":{"duration":0.012947,"end_time":"2025-04-25T17:06:48.896441","exception":false,"start_time":"2025-04-25T17:06:48.883494","status":"completed"},"tags":[]},"source":["### Create The embeddings database\n","\n","Finally We will merge everthing we have build by creating the vector database we will send the chunks to our embed function in batches so that we wont have to make unnesessary api calls every time we have taken the batch size to be 100 this is done to keep the chunks size below the limit of the function for more about the api calls and token limit chek the [api documentation](https://ai.google.dev/gemini-api/docs/models)"]},{"cell_type":"code","execution_count":16,"id":"d4a29cd2","metadata":{"execution":{"iopub.execute_input":"2025-04-25T17:06:48.922055Z","iopub.status.busy":"2025-04-25T17:06:48.921624Z","iopub.status.idle":"2025-04-25T17:07:01.977366Z","shell.execute_reply":"2025-04-25T17:07:01.976225Z"},"papermill":{"duration":13.069271,"end_time":"2025-04-25T17:07:01.979479","exception":false,"start_time":"2025-04-25T17:06:48.910208","status":"completed"},"tags":[]},"outputs":[],"source":["DB_NAME = \"googlecardb\"\n","\n","embed_fn = GeminiEmbeddingFunction()\n","embed_fn.document_mode = True\n","\n","chroma_client = chromadb.Client()\n","db = chroma_client.get_or_create_collection(name=DB_NAME, embedding_function=embed_fn)\n","current_id_offset = 0\n","total_chunks = len(chunks)\n","API_BATCH_SIZE = 100\n","\n","batch_size = 100\n","\n","for i in range(0, total_chunks, API_BATCH_SIZE):\n","    batch_chunks = chunks[i : i + API_BATCH_SIZE]\n","    \n","    batch_ids = [str(current_id_offset + j) for j in range(len(batch_chunks))]\n","    current_id_offset += len(batch_chunks)\n","\n","    db.add(documents=batch_chunks,ids=batch_ids)\n","    "]},{"cell_type":"code","execution_count":17,"id":"b4e3e92b","metadata":{"execution":{"iopub.execute_input":"2025-04-25T17:07:01.99808Z","iopub.status.busy":"2025-04-25T17:07:01.997678Z","iopub.status.idle":"2025-04-25T17:07:02.00658Z","shell.execute_reply":"2025-04-25T17:07:02.005341Z"},"papermill":{"duration":0.01998,"end_time":"2025-04-25T17:07:02.008334","exception":false,"start_time":"2025-04-25T17:07:01.988354","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["789"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["db.count()"]},{"cell_type":"markdown","id":"9c868712","metadata":{"papermill":{"duration":0.00809,"end_time":"2025-04-25T17:07:02.025222","exception":false,"start_time":"2025-04-25T17:07:02.017132","status":"completed"},"tags":[]},"source":["### Prompting for the chatbot\n","\n","Add additional prompting to the llm so that it could give the answer in the way you desire. First the query you have given will feth the relevant documents from the vector database we have created this technique is also called RAG(retrival augument generation). The  we will give the the fetched data as context to the llm  so that it can give the answer based on the latest information about the SDK this technique can also be termed as Grounding where the gemini API uses google to feth the lates information about the query and answers based on that latest information provided."]},{"cell_type":"code","execution_count":18,"id":"0e802c82","metadata":{"execution":{"iopub.execute_input":"2025-04-25T17:07:02.043003Z","iopub.status.busy":"2025-04-25T17:07:02.042564Z","iopub.status.idle":"2025-04-25T17:07:07.572428Z","shell.execute_reply":"2025-04-25T17:07:07.569968Z"},"papermill":{"duration":5.543638,"end_time":"2025-04-25T17:07:07.577064","exception":false,"start_time":"2025-04-25T17:07:02.033426","status":"completed"},"tags":[]},"outputs":[{"data":{"text/markdown":["Okay, let's break down how to use the Google Gen AI SDK.\n","\n","1.  **Installation:**\n","    *   First, you need to install the SDK using pip:\n","        ```bash\n","        pip install google-genai\n","        ```\n","\n","2.  **Imports:**\n","    *   Then, import the necessary modules:\n","        ```python\n","        from google import genai\n","        from google.genai import types\n","        ```\n","\n","3.  **Create a Client:**\n","    *   You'll need to create a client instance to interact with the Generative AI APIs.  You have two options here, depending on whether you want to use the Gemini Developer API or the Gemini API in Vertex AI.\n","\n","    *   **For Gemini Developer API:**\n","        ```python\n","        client = genai.Client(api_key='YOUR_API_KEY')\n","        ```\n","        *   Remember to replace `'YOUR_API_KEY'` with your actual API key.\n","\n","    *   **For Vertex AI API:**\n","        ```python\n","        client = genai.Client(vertexai=True, project='your-project-id', location='us-central1')\n","        ```\n","        *   Replace `'your-project-id'` with your Google Cloud project ID.\n","        *   The `location` parameter specifies the region (e.g., `'us-central1'`).\n","\n","    *   **Using Environment Variables (Optional):**  Instead of directly passing the API key or project details, you can configure environment variables.\n","\n","        *   **Gemini Developer API:**\n","            ```bash\n","            export GOOGLE_API_KEY='your-api-key'\n","            ```\n","        *   **Gemini API in Vertex AI:**\n","            ```bash\n","            export GOOGLE_GENAI_USE_VERTEXAI=true\n","            export GOOGLE_CLOUD_PROJECT='your-project-id'\n","            export GOOGLE_CLOUD_LOCATION='us-central1'\n","            ```\n","        *   After setting the environment variables, you can create the client like this:\n","            ```python\n","            client = genai.Client()\n","            ```\n","\n","4.  **API Selection:**\n","    *   The SDK defaults to using beta API endpoints. To use stable API endpoints, set the API version to `v1` using `http_options`.\n","\n","    *   **For Vertex AI:**\n","        ```python\n","        client = genai.Client(vertexai=True, project='your-project-id', location='us-central1', http_options=types.HttpOptions(api_version='v1'))\n","        ```\n","\n","    *   **For Gemini Developer API:**\n","        ```python\n","        client = genai.Client(api_key='YOUR_API_KEY', http_options=types.HttpOptions(api_version='v1alpha'))\n","        ```\n","\n","5.  **Models:**\n","    *   The `client.models` module is how you access model inferencing and model getters.\n","\n","6.  **Generate Content:**\n","\n","    *   **With Text Content:**\n","        ```python\n","        response = client.models.generate_content(model='gemini-2.0-flash-001', contents='Why is the sky blue?')\n","        print(response.text)\n","        ```\n","\n","    *   **With Uploaded File (Gemini Developer API only):**\n","        ```python\n","        # Download the file (if you don't already have it)\n","        # !wget -q https://storage.googleapis.com/generativeai-downloads/data/a11.txt\n","\n","        file = client.files.upload(file='a11.txt')\n","        response = client.models.generate_content(model='gemini-2.0-flash-001', contents=['Could you summarize this file?', file])\n","        print(response.text)\n","        ```\n","\n","7. **Types**:\n","    *   Parameter types can be specified as either dictionaries( TypedDict ) or Pydantic Models . Pydantic model types are available in the types module.\n"],"text/plain":["<IPython.core.display.Markdown object>"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["from IPython.display import Markdown\n","embed_fn.document_mode = False\n","\n","query = \"how to use google-genai sdk\"\n","\n","result = db.query(query_texts=[query], n_results=5)\n","\n","\n","context = result['documents'][0]\n","\n","prompt = f\"\"\"\n","Role : You are a teacher for the new google genai SDK \n","\n","\n","Answer the following question based ONLY on the provided context:\n","\n","Context:\n","{context}\n","\n","Question:\n","{query}\n","\n","Answer:\n","\"\"\"\n","\n","response = client.models.generate_content(\n","     model='gemini-2.0-flash',\n","     contents=prompt,\n","    \n",")\n","\n","Markdown(response.text)\n","\n"]},{"cell_type":"markdown","id":"31e82ae3","metadata":{"papermill":{"duration":0.012687,"end_time":"2025-04-25T17:07:07.603452","exception":false,"start_time":"2025-04-25T17:07:07.590765","status":"completed"},"tags":[]},"source":["## Future Possibilities\n","\n","In the future we could add the gemini cookbook to this project so we could get the latest use cases of the gemini api with explanation\n","This project aims to enhance the adoption of new SDK.\n"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30918,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"papermill":{"default_parameters":{},"duration":103.327763,"end_time":"2025-04-25T17:07:11.099725","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-04-25T17:05:27.771962","version":"2.6.0"}},"nbformat":4,"nbformat_minor":5}